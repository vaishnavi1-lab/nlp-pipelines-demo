# -*- coding: utf-8 -*-
"""Nlp_pipelines_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QgWI4DEts5okpQnOH6xO0-wTFzGcEpxE
"""



"""

```
#  NLP Pipelines with Hugging Face Transformers
# üß† NLP Pipelines with Transformers

This project showcases 8 major NLP tasks using Hugging Face's `transformers` library:

1. ‚úÖ Text Classification
2. ‚ùì Zero-Shot Classification
3. ‚úçÔ∏è Text Generation
4. üß© Masked Language Modeling
5. üßæ Named Entity Recognition (Token Classification)
6. üîç Question Answering
7. ‚úÇÔ∏è Summarization
8. üåê Translation

## üîß Setup

```bash
pip install transformers torch

```

"""

from transformers import pipeline

'''1. Text Classification
Goal: Put the text into a category (positive/negative, spam/ham, etc.)

Used for: Sentiment analysis, spam detection, topic labeling'''


classifier = pipeline("sentiment-analysis")
classifier(["I've been waiting for a Hugging Face course my Whole life","I hate this Generation so much","My meeting on 5PM today"])

'''2. Zero-Shot Classification
Goal: Classify text into categories without training the model on those categories.

Used for: Dynamic categorization when labels are unknown at training time.'''


classifier = pipeline("zero-shot-classification")
classifier("This is the course about the transformers library", candidate_labels = ["education","Positive","Business"] )

'''3.1 Text Generation
Goal: Generate new text based on a prompt.

Used for: Story writing, content generation, AI chatbots.'''


generator = pipeline("text-generation")
generator("The Generative AI is the Most Importat for")

# 3.2 Text Generation
# Goal: Generate new text based on a prompt.
# Used for: Story writing, content generation, AI chatbots.

from transformers import pipeline

# Create a text generation pipeline using the "distilgpt2" model
generator = pipeline("text-generation", model="distilgpt2")

# Generate text based on the provided prompt
# max_length: The maximum length of the generated text (including the prompt).
# num_return_sequences: The number of different sequences to generate.
generator("In this Gen-Z world, the generative AI play a Most Imortant Role is", max_length=30, num_return_sequences=2)

'''4. Text Completion (Masked Language Modeling)
Goal: Fill in the missing word in a sentence.

Used for: Auto-completion, grammar correction'''

unmasker = pipeline("fill-mask")
unmasker("The Gen AI teach you all about <mask> model", top_k = 2)

''' 5. Token Classification
Goal: Label each word/token with a category.

Used for: Named Entity Recognition (NER), Part-of-Speech (POS) tagging.'''


ner = pipeline("ner", grouped_entities = True)
ner("My name is Vaishnavi and I Find Job In Gen AI and Data Analyatics Domain")

'''6. Question Answering
Goal: Find the answer from a given context.

Used for: Chatbots, search engines, Q&A systems.'''

question_answerer = pipeline("question-answering")
question_answerer(
    question = "In which domain I look for Job?",
    context = "My name is Vaishnavi and I Find Job In Gen AI and Data Analyatics Domain"
)

'''7. Summarization
Goal: Create a short summary from a long text.

Used for: News summaries, article previews.'''

summarizer = pipeline("summarization")
summarizer("""Introduction In the modern landscape of business, organizations must constantly seek ways to harness technological advancements to stay ahead of the curve. Generative AI is a major realm that has seen explosive growth in recent years. Gartner predicts that by 2026, more than 80% of businesses will use Generative AI technology. This is a significant increase from less than 5% in 2023. Generative AI has introduced a paradigm shift in data analytics and its applications. With just a few words of prompt, you can get answers in the form of text, image, audio, or any form desired.  This is achieved through understanding and replicating the underlying data structure rather than predictions done by traditional AI models. With deep learning techniques, Generative AI also finds applications across numerous industries and has witnessed rapid growth in just one year. Through this blog, we will dive deeper into the principles and models of Generative AI and its applications in data analytics. We will also explore challenges and opportunities in adopting the technology and future path that lie ahead for Gen AI.
""", max_length=100, min_length=30)

'''8. Translation
Goal: Translate from one language to another.

Used for: Multilingual apps, document conversion.'''


translator = pipeline("translation", model = "Helsinki-NLP/opus-mt-en-hi")
translator("I want to learn modern Technologies which help me to get job in this AI world")



# 1. Text Classification
def text_classification():
    classifier = pipeline("text-classification")
    text = "I absolutely love this phone!"
    result = classifier(text)
    print("1. Text Classification:\n", result, "\n")

# 2. Zero-Shot Classification
def zero_shot_classification():
    classifier = pipeline("zero-shot-classification")
    text = "This mobile has a long battery life and great camera."
    labels = ["technology", "sports", "politics"]
    result = classifier(text, candidate_labels=labels)
    print("2. Zero-Shot Classification:\n", result, "\n")

# 3. Text Generation
def text_generation():
    generator = pipeline("text-generation")
    prompt = "In the future, artificial intelligence will"
    result = generator(prompt, max_length=30, num_return_sequences=1)
    print("3. Text Generation:\n", result, "\n")

# 4. Masked Language Modeling
def masked_language_modeling():
    fill_mask = pipeline("fill-mask")
    masked_sentence = "Machine learning is the <mask> of AI."
    result = fill_mask(masked_sentence)
    print("4. Masked Language Modeling:\n", result, "\n")

# 5. Token Classification (NER)
def token_classification():
    ner = pipeline("token-classification")
    text = "Elon Musk founded SpaceX in the United States."
    result = ner(text)
    print("5. Token Classification (NER):\n", result, "\n")

# 6. Question Answering
def question_answering():
    qa = pipeline("question-answering")
    context = "Barack Obama was born in Hawaii. He was the 44th president of the USA."
    question = "Where was Obama born?"
    result = qa(question=question, context=context)
    print("6. Question Answering:\n", result, "\n")

# 7. Summarization
def summarization():
    summarizer = pipeline("summarization")
    long_text = ("Artificial intelligence and machine learning are rapidly changing the world. "
                 "They are being used in industries such as healthcare, finance, and transportation "
                 "to improve efficiency, reduce costs, and enhance decision-making.")
    result = summarizer(long_text, max_length=40, min_length=10, do_sample=False)
    print("7. Summarization:\n", result, "\n")

# 8. Translation
def translation():
    translator = pipeline("translation", model="Helsinki-NLP/opus-mt-en-hi")
    text = "I love learning natural language processing."
    result = translator(text)
    print("8. Translation (English to Hindi):\n", result, "\n")

# Run all
if __name__ == "__main__":
    text_classification()
    zero_shot_classification()
    text_generation()
    masked_language_modeling()
    token_classification()
    question_answering()
    summarization()
    translation()